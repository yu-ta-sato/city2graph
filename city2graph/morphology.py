"""Module for creating morphological graphs from urban data."""

import itertools
import logging
import math
import warnings

import geopandas as gpd
import libpysal
import networkx as nx
import numpy as np
import pandas as pd
from scipy.spatial import KDTree
from scipy.spatial.distance import pdist
from shapely.creation import linestrings as sh_linestrings
from shapely.geometry import Point

from .utils import create_tessellation
from .utils import dual_graph
from .utils import filter_graph_by_distance
from .utils import gdf_to_nx
from .utils import nx_to_gdf
from .utils import segments_to_graph

# Define the public API for this module
__all__ = [
    "morphological_graph",
    "private_to_private_graph",
    "private_to_public_graph",
    "public_to_public_graph",
]

logger = logging.getLogger(__name__)


# ============================================================================
# MAIN MORPHOLOGICAL GRAPH FUNCTION
# ============================================================================


def morphological_graph(
    buildings_gdf: gpd.GeoDataFrame,
    segments_gdf: gpd.GeoDataFrame,
    center_point: gpd.GeoSeries | gpd.GeoDataFrame | None = None,
    distance: float | None = None,
    clipping_buffer: float = math.inf,
    primary_barrier_col: str | None = "barrier_geometry",
    contiguity: str = "queen",
    keep_buildings: bool = False,
    ) -> tuple[dict[str, gpd.GeoDataFrame], dict[tuple[str, str, str], gpd.GeoDataFrame]]:
    """
    Create a morphological graph from buildings and street segments.

    This function creates a comprehensive morphological graph that captures relationships
    between private spaces (building tessellations) and public spaces (street segments).
    The graph includes three types of relationships: private-to-private adjacency,
    public-to-public connectivity, and private-to-public interfaces.

    The 'private_id' for tessellation cells is derived from 'tess_id' (generated by
    `create_tessellation`) or assigned sequentially if 'tess_id' doesn't directly map.
    The 'public_id' for street segments is taken directly from the index of `segments_gdf`.

    Parameters
    ----------
    buildings_gdf : geopandas.GeoDataFrame
        GeoDataFrame containing building polygons. Should contain Polygon or MultiPolygon geometries.
    segments_gdf : geopandas.GeoDataFrame
        GeoDataFrame containing street segments. Should contain LineString geometries.
    center_point : Union[gpd.GeoSeries, gpd.GeoDataFrame], optional
        Center point(s) for spatial filtering. If provided with distance parameter,
        only segments within the specified distance will be included.
    distance : float, optional
        Maximum distance from ``center_point`` for spatial filtering. When
        specified, street segments beyond this shortest-path distance are
        removed and tessellation cells are kept only if their own distance via
        these segments does not exceed this value.
    clipping_buffer : float, default=math.inf
        Additional buffer distance (non-negative) to be added to `distance` when
        `distance` and `center_point` are specified.
        This sum (`distance + clipping_buffer`) is used as the radius for filtering
        `segs_buffer` (segments used for tessellation context).
        If `clipping_buffer` is `math.inf` (and `distance` is set), `segs_buffer` is
        filtered by `distance` alone.
        The `max_distance` for `_filter_adjacent_tessellation` becomes
        `distance + clipping_buffer` (this evaluates to `math.inf` if `clipping_buffer`
        is `math.inf` or if `distance` is not set).
        If `distance` is not provided, `clipping_buffer` is effectively ignored for
        `segs_buffer` filtering, and `max_distance` for `_filter_adjacent_tessellation`
        defaults to `math.inf`.
        Must be non-negative. Defaults to `math.inf`.
    primary_barrier_col : str, optional
        Column name containing alternative geometry for public spaces. If specified and exists,
        this geometry will be used instead of the main geometry column for tessellation barriers.
        Default is "barrier_geometry".
    contiguity : str, default="queen"
        Type of spatial contiguity for private-to-private connections.
        Must be either "queen" or "rook".
    keep_buildings : bool, default=False
        If True, preserves building information in the tessellation output.

    Returns
    -------
    tuple[dict[str, gpd.GeoDataFrame], dict[tuple[str, str, str], gpd.GeoDataFrame]]
        A tuple containing:
        - nodes: Dictionary with keys "private" and "public" containing node GeoDataFrames
        - edges: Dictionary with relationship type keys containing edge GeoDataFrames

    Raises
    ------
    TypeError
        If buildings_gdf or segments_gdf are not GeoDataFrames.
    ValueError
        If contiguity parameter is not "queen" or "rook".
        If clipping_buffer is negative.

    Notes
    -----
    The function first filters the street network by `distance` (resulting in `segs`).
    A `segs_buffer` GeoDataFrame is also created for tessellation context, potentially
    filtered by `distance + clipping_buffer` or `distance` if `center_point` and
    `distance` are provided. This `segs_buffer` is used to create enclosures and
    tessellations.
    It then establishes three types of relationships:
    1. Private-to-private: Adjacency between tessellation cells (handled by private_to_private_graph)
    2. Public-to-public: Topological connectivity between street segments
    3. Private-to-public: Spatial interfaces between tessellations and streets

    The output follows a heterogeneous graph structure suitable for network analysis
    of urban morphology.
    """
    # Define fixed ID column names
    _final_private_id_col = "private_id"
    _final_public_id_col = "public_id"

    # Validate input GeoDataFrames (includes geometry type checks)
    _validate_input_gdfs(buildings_gdf, segments_gdf)

    # Validate contiguity parameter
    if contiguity not in {"queen", "rook"}:
        msg = "contiguity must be 'queen' or 'rook'"
        raise ValueError(msg)

    # Validate clipping_buffer
    if clipping_buffer < 0:
        msg = "clipping_buffer cannot be negative."
        raise ValueError(msg)

    # Ensure CRS consistency between buildings and segments
    segments_gdf = _ensure_crs_consistency(buildings_gdf, segments_gdf)

    # Assign the original index of segments_gdf to _final_public_id_col
    # A copy is made to avoid SettingWithCopyWarning if segments_gdf might be a slice,
    # especially before adding/modifying a column.
    segments_gdf = segments_gdf.copy()
    segments_gdf[_final_public_id_col] = segments_gdf.index  # Use original index as public ID

    # Convert segments to a graph representation for efficient filtering.
    if not segments_gdf.empty:
        # segments_to_graph returns nodes and edges with a MultiIndex.
        # gdf_to_nx converts these to a NetworkX graph.
        nodes_unfiltered, edges_unfiltered = segments_to_graph(segments_gdf)
        graph_for_filtering = gdf_to_nx(nodes=nodes_unfiltered, edges=edges_unfiltered)
    else:
        # Create empty structures to avoid errors downstream
        nodes_unfiltered, edges_unfiltered = segments_to_graph(segments_gdf)
        graph_for_filtering = nx.Graph()

    # Filter segments by network distance for the final graph if center_point and distance are provided
    if center_point is not None and distance is not None and not segments_gdf.empty:
        segs_graph = filter_graph_by_distance(graph_for_filtering, center_point, distance)
        segs = nx_to_gdf(segs_graph, nodes=False, edges=True)
    else:
        segs = edges_unfiltered

    # Create a buffered version of the graph for tessellation creation (segs_buffer)
    # This segs_buffer is used for _prepare_barriers -> create_tessellation
    # and as the segments context for _filter_adjacent_tessellation.
    if center_point is not None and distance is not None and not segments_gdf.empty:
        if not math.isinf(clipping_buffer):
            # Finite clipping_buffer: use distance + clipping_buffer for segs_buffer radius
            segs_buffer_radius = distance + clipping_buffer
            segs_buffer_graph = filter_graph_by_distance(
                graph_for_filtering, center_point, segs_buffer_radius,
            )
            segs_buffer = nx_to_gdf(segs_buffer_graph, nodes=False, edges=True)
        else:  # clipping_buffer is math.inf
            # Fallback to 'distance' as radius for segs_buffer
            segs_buffer_graph = filter_graph_by_distance(
                graph_for_filtering, center_point, distance,
            )
            segs_buffer = nx_to_gdf(segs_buffer_graph, nodes=False, edges=True)
    else:
        # No center_point or no distance, so segs_buffer is not filtered by distance
        segs_buffer = edges_unfiltered

    # Prepare barriers from the buffered segments (segs_buffer) for tessellation
    barriers = _prepare_barriers(segs_buffer, primary_barrier_col)
    # Create tessellation based on buildings and prepared barriers
    tessellation = create_tessellation(
        buildings_gdf,
        primary_barriers=None if barriers.empty else barriers, # Use barriers if available
    )

    # Rename tessellation ID column (typically 'tess_id') to the fixed private ID name
    tessellation = tessellation.rename(columns={"tess_id": _final_private_id_col})

    # Ensure the fixed private ID column exists, creating a sequential ID if necessary
    if _final_private_id_col not in tessellation.columns:
        tessellation[_final_private_id_col] = range(len(tessellation)) # Assign sequential private IDs

    # Determine max_distance for filtering tessellation adjacent to segments
    max_distance_for_adj_filter = distance + clipping_buffer if distance is not None else math.inf

    # Filter tessellation to only include cells adjacent to the (potentially filtered) 'segs'
    tessellation = _filter_adjacent_tessellation(
        tessellation,
        segs, # Use 'segs' (final graph segments) for adjacency check
        max_distance=max_distance_for_adj_filter, # Max distance for adjacency
    )

    # Further filter tessellation by network distance if center_point and distance are specified
    if center_point is not None and distance is not None:
        tessellation = _filter_tessellation_by_network_distance(
            tessellation,
            segs, # Use 'segs' for network distance calculation
            center_point,
            distance, # Max network distance
        )

    # Optionally preserve building information by joining tessellation with buildings
    if keep_buildings:
        tessellation = _add_building_info(tessellation, buildings_gdf)

    # Determine group_col for private_to_private_graph
    group_col_for_priv_priv = "enclosure_index"
    if group_col_for_priv_priv not in tessellation.columns:
        if not tessellation.empty:
            logger.warning(
                "Column '%s' not found in tessellation. "
                "Private-to-private graph will not use grouping.",
                group_col_for_priv_priv,
            )
        group_col_for_priv_priv = None

    # Create private-to-private graph (adjacency between tessellation cells)
    priv_priv = private_to_private_graph(
        tessellation,
        group_col=group_col_for_priv_priv,
        contiguity=contiguity,
    )

    # Create public-to-public graph (connectivity between street segments)
    pub_pub = public_to_public_graph(segs) # Use 'segs' (final graph segments)

    # Create private-to-public graph (interfaces between tessellation and streets)
    priv_pub = private_to_public_graph(
        tessellation,
        segs, # Use 'segs' (final graph segments)
        primary_barrier_col=primary_barrier_col, # Optional alternative geometry for public spaces
    )

    # Log warning if no private-public connections found
    if priv_pub.empty:
        logger.warning("No private to public connections found")

    # Organize output as a heterogeneous graph structure (nodes and edges dictionaries)
    nodes = {
        "private": _set_node_index(tessellation, _final_private_id_col), # Private nodes (tessellation)
        "public": _set_node_index(segs, _final_public_id_col), # Public nodes (segments)
    }
    edges = {
        ("private", "touched_to", "private"): _set_edge_index(
            priv_priv, "from_private_id", "to_private_id", # Private-private edges
        ),
        ("public", "connected_to", "public"): _set_edge_index(
            pub_pub, "from_public_id", "to_public_id", # Public-public edges
        ),
        ("private", "faced_to", "public"): _set_edge_index(
            priv_pub, "private_id", "public_id", # Private-public edges
        ),
    }
    return nodes, edges # Return the structured graph data


# ============================================================================
# PRIVATE TO PRIVATE GRAPH FUNCTIONS
# ============================================================================


def private_to_private_graph(
    private_gdf: gpd.GeoDataFrame,
    group_col: str | None = None,
    contiguity: str = "queen",
) -> gpd.GeoDataFrame:
    """
    Create edges between contiguous private polygons based on spatial adjacency.

    This function identifies spatial adjacency relationships between private polygons
    (e.g., tessellation cells) using either Queen or Rook contiguity criteria.
    Optionally groups connections within specified groups (e.g., enclosures).
    The input `private_gdf` is expected to have a 'private_id' column.

    Parameters
    ----------
    private_gdf : geopandas.GeoDataFrame
        GeoDataFrame containing private space polygons. Must contain a 'private_id' column.
    group_col : str, optional
        Column name for grouping connections. Only polygons within the same group
        will be connected. If None, all polygons are considered as one group.
    contiguity : str, default="queen"
        Type of spatial contiguity to use. Must be either "queen" or "rook".
        Queen contiguity includes vertex neighbors, Rook includes only edge neighbors.

    Returns
    -------
    geopandas.GeoDataFrame
        GeoDataFrame containing edge geometries between adjacent polygons.
        Columns include from_private_id, to_private_id, group column, and geometry.

    Raises
    ------
    TypeError
        If private_gdf is not a GeoDataFrame.
    ValueError
        If contiguity not in {"queen", "rook"}, or if group_col doesn't exist.

    Notes
    -----
    The function uses libpysal's spatial weights to determine adjacency relationships.
    Edge geometries are created as LineStrings connecting polygon centroids.
    Self-connections and duplicate edges are automatically filtered out.
    The input private_gdf is expected to have a 'private_id' column.
    """
    # Input validation
    _validate_single_gdf_input(private_gdf, "private_gdf", {"Polygon", "MultiPolygon"})

    _id_col = "private_id" # Fixed ID column name for private polygons

    # If not empty, require the ID column
    if not private_gdf.empty and _id_col not in private_gdf.columns:
        msg = f"Expected ID column '{_id_col}' not found in private_gdf."
        raise ValueError(msg)

    # Validate that the contiguity type is supported
    if contiguity not in {"queen", "rook"}:
        msg = "contiguity must be either 'queen' or 'rook'"
        raise ValueError(msg)

    # Handle empty or insufficient data: return empty edges GeoDataFrame
    if private_gdf.empty or len(private_gdf) < 2:
        group_cols = [group_col or "group"]
        return _create_empty_edges_gdf(
            private_gdf.crs, "from_private_id", "to_private_id", group_cols,
        )

    # Validate that the group column exists if specified
    if group_col and group_col not in private_gdf.columns:
        msg = f"group_col '{group_col}' not found in private_gdf columns"
        raise ValueError(msg)

    # Reset index for consistent spatial weights computation by libpysal
    gdf_indexed = private_gdf.reset_index(drop=True)

    # Create spatial weights matrix (Queen or Rook contiguity)
    spatial_weights = _create_spatial_weights(gdf_indexed, contiguity)

    # Extract adjacency relationships from the spatial weights matrix
    adjacency_data = _extract_adjacency_relationships(
        spatial_weights, gdf_indexed, _id_col, group_col,
    )

    # Create edge geometries (LineStrings connecting centroids of adjacent polygons)
    edges_gdf_data = _create_adjacency_edges(adjacency_data, gdf_indexed, group_col or "group")

    # Convert the DataFrame with edge geometries to a GeoDataFrame
    return gpd.GeoDataFrame(
        edges_gdf_data, # Data including 'from_private_id', 'to_private_id', group, and geometry
        geometry="geometry",
        crs=private_gdf.crs, # Preserve original CRS
    )

# ============================================================================
# PRIVATE TO PUBLIC GRAPH FUNCTIONS
# ============================================================================

def private_to_public_graph(
    private_gdf: gpd.GeoDataFrame,
    public_gdf: gpd.GeoDataFrame,
    primary_barrier_col: str | None = None,
    tolerance: float = 1.0,
) -> gpd.GeoDataFrame:
    """
    Create edges between private polygons and nearby public geometries.

    This function identifies spatial relationships between private spaces (tessellations)
    and public spaces (street segments) by finding intersections between buffered public
    geometries and private polygons.
    Input GDFs are expected to have 'private_id' and 'public_id' columns respectively.

    Parameters
    ----------
    private_gdf : geopandas.GeoDataFrame
        GeoDataFrame containing private space polygons. Expected to have a 'private_id' column.
    public_gdf : geopandas.GeoDataFrame
        GeoDataFrame containing public space geometries (typically LineStrings).
        Expected to have a 'public_id' column.
    primary_barrier_col : str, optional
        Column name for alternative public geometry. If specified and exists,
        this geometry will be used instead of the main geometry column.
    tolerance : float, default=1.0
        Buffer distance for public geometries to detect proximity to private spaces.

    Returns
    -------
    geopandas.GeoDataFrame
        GeoDataFrame containing edge geometries between private and public spaces.
        Columns include private_id, public_id, and geometry.

    Raises
    ------
    TypeError
        If private_gdf or public_gdf are not GeoDataFrames.
    ValueError
        If 'private_id' or 'public_id' columns are missing from input GDFs.

    Notes
    -----
    Edge geometries are created as LineStrings connecting the centroids of
    private polygons and public geometries. The function uses spatial joins
    to identify overlapping areas within the specified tolerance.
    Input GDFs are expected to have 'private_id' and 'public_id' columns respectively.
    """
    # Input validation
    _validate_single_gdf_input(private_gdf, "private_gdf", {"Polygon", "MultiPolygon"})
    _validate_single_gdf_input(public_gdf, "public_gdf", {"LineString"})

    _priv_id_col = "private_id" # Fixed ID column name for private spaces
    _pub_id_col = "public_id"   # Fixed ID column name for public spaces

    # Handle empty data: return empty edges GeoDataFrame
    if private_gdf.empty or public_gdf.empty:
        return _create_empty_edges_gdf(private_gdf.crs, _priv_id_col, _pub_id_col)

    # Ensure required ID columns exist in the input GeoDataFrames
    if _priv_id_col not in private_gdf.columns:
        msg = f"Expected ID column '{_priv_id_col}' not found in private_gdf."
        raise ValueError(msg)
    if _pub_id_col not in public_gdf.columns:
        msg = f"Expected ID column '{_pub_id_col}' not found in public_gdf."
        raise ValueError(msg)

    # Ensure CRS consistency between private and public GeoDataFrames
    public_gdf = _ensure_crs_consistency(private_gdf, public_gdf)

    # Determine which geometry column to use for public spaces (main or alternative)
    join_geom_series = (public_gdf[primary_barrier_col]
                        if primary_barrier_col and primary_barrier_col in public_gdf.columns
                        else public_gdf.geometry)

    # Create buffered geometries for public spaces to detect proximity
    buffered_public_data = {_pub_id_col: public_gdf[_pub_id_col]} # Keep public IDs
    buffered_public = gpd.GeoDataFrame(
        buffered_public_data,
        geometry=join_geom_series.buffer(tolerance), # Buffer the selected public geometry
        crs=public_gdf.crs,
    )

    # Perform spatial join to find intersections between private polygons and buffered public geometries
    joined = gpd.sjoin(
        private_gdf[[_priv_id_col, "geometry"]], # Private polygons with their IDs
        buffered_public, # Buffered public geometries with their IDs
        how="inner", # Keep only intersecting pairs
        predicate="intersects", # Use intersection predicate
    )

    # If intersections found, keep only the ID columns
    if not joined.empty:
        id_cols_to_keep = [_priv_id_col, _pub_id_col]
        joined = joined[id_cols_to_keep] # Select relevant ID columns

    # Drop duplicate pairs of (private_id, public_id)
    joined = joined.drop_duplicates()

    # Create maps of centroids for private and public geometries, indexed by their IDs
    private_centroids_map = (private_gdf.drop_duplicates(subset=[_priv_id_col])
                             .set_index(_priv_id_col).geometry.centroid)
    public_centroids_map = (public_gdf.drop_duplicates(subset=[_pub_id_col])
                            .set_index(_pub_id_col).geometry.centroid)

    # Prepare to add edge geometries to the joined DataFrame
    joined_with_geom = joined.copy()

    # Get centroid geometries for each pair in the 'joined' DataFrame
    p1_geoms = private_centroids_map.loc[joined_with_geom[_priv_id_col]].reset_index(drop=True)
    p2_geoms = public_centroids_map.loc[joined_with_geom[_pub_id_col]].reset_index(drop=True)

    # Stack the coordinates of the centroids to create LineString geometries
    coords_p1 = np.array(list(zip(p1_geoms.x, p1_geoms.y, strict=True))) # Coordinates for private centroids
    coords_p2 = np.array(list(zip(p2_geoms.x, p2_geoms.y, strict=True))) # Coordinates for public centroids
    line_coords = np.stack((coords_p1, coords_p2), axis=1) # Stack coordinates for LineString creation
    joined_with_geom["geometry"] = list(sh_linestrings(line_coords)) # Create LineStrings

    # Convert the DataFrame with edge geometries to a GeoDataFrame
    # Columns are already named _priv_id_col ("private_id") and _pub_id_col ("public_id").
    return gpd.GeoDataFrame(joined_with_geom, geometry="geometry", crs=private_gdf.crs)


# ============================================================================
# PUBLIC TO PUBLIC GRAPH FUNCTIONS
# ============================================================================


def public_to_public_graph(
    public_gdf: gpd.GeoDataFrame,
) -> gpd.GeoDataFrame:
    """
    Create edges between connected public segments based on topological connectivity.

    This function identifies topological connections between public space geometries
    (typically street segments) using the dual graph approach to find segments
    that share endpoints or connection points.
    The input `public_gdf` must have a 'public_id' column that will be used to
    identify segments.

    Parameters
    ----------
    public_gdf : geopandas.GeoDataFrame
        GeoDataFrame containing public space geometries (typically LineString).
        Must have a 'public_id' column.

    Returns
    -------
    geopandas.GeoDataFrame
        GeoDataFrame containing edge geometries between connected public segments.
        The GeoDataFrame will have 'from_public_id' and 'to_public_id' columns.

    Raises
    ------
    TypeError
        If public_gdf is not a GeoDataFrame.
    ValueError
        If 'public_id' column is missing from public_gdf.


    Notes
    -----
    The function uses the dual graph approach where each LineString becomes a node,
    and edges represent topological connections between segments. Edge geometries
    are created as LineStrings connecting the centroids of connected segments.
    """
    # Input validation
    _validate_single_gdf_input(public_gdf, "public_gdf", {"LineString"})

    # Handle empty or insufficient data: return empty edges GeoDataFrame
    if public_gdf.empty or len(public_gdf) < 2:
        return _create_empty_edges_gdf(public_gdf.crs, "from_public_id", "to_public_id")

    # Ensure 'public_id' column exists
    if "public_id" not in public_gdf.columns:
        msg = "Input `public_gdf` must have a 'public_id' column."
        raise ValueError(msg)

    # Use 'public_id' as the index for dual_graph processing
    public_gdf_indexed = public_gdf.set_index("public_id")

    # Create dual graph (nodes are segments, edges are connections)
    _, edges_gdf_dual = dual_graph(
        public_gdf_indexed, keep_original_geom=True,
    )

    # Rename the MultiIndex levels for clarity and consistency
    if isinstance(edges_gdf_dual.index, pd.MultiIndex):
        edges_gdf_dual.index.names = ["from_public_id", "to_public_id"]

    if not edges_gdf_dual.empty:
        return edges_gdf_dual.reset_index()

    return edges_gdf_dual


# ============================================================================
# HELPER FUNCTIONS FOR VALIDATION AND DATA PROCESSIÃ§NG
# ============================================================================


def _validate_input_gdfs(buildings_gdf: gpd.GeoDataFrame, segments_gdf: gpd.GeoDataFrame) -> None:
    """
    Validate input GeoDataFrames for the morphological graph function.

    Parameters
    ----------
    buildings_gdf : geopandas.GeoDataFrame
        GeoDataFrame containing building polygons
    segments_gdf : geopandas.GeoDataFrame
        GeoDataFrame containing street segments

    Raises
    ------
    TypeError
        If inputs are not GeoDataFrames
    ValueError
        If geometry types are invalid
    """
    # Check if buildings_gdf is a GeoDataFrame
    if not isinstance(buildings_gdf, gpd.GeoDataFrame):
        msg = "buildings_gdf must be a GeoDataFrame"
        raise TypeError(msg)
    # Check if segments_gdf is a GeoDataFrame
    if not isinstance(segments_gdf, gpd.GeoDataFrame):
        msg = "segments_gdf must be a GeoDataFrame"
        raise TypeError(msg)

    # Validate geometry types for non-empty buildings_gdf
    if not buildings_gdf.empty:
        building_geom_types = buildings_gdf.geometry.geom_type.unique()
        if not all(geom_type in {"Polygon", "MultiPolygon"} for geom_type in building_geom_types):
            msg = (
                f"buildings_gdf must contain only Polygon or MultiPolygon geometries. "
                f"Found: {', '.join(building_geom_types)}"
            )
            raise ValueError(msg)

    # Validate geometry types for non-empty segments_gdf
    if not segments_gdf.empty:
        # Assuming LineString is required for operations like dual_graph
        segment_geom_types = segments_gdf.geometry.geom_type.unique()
        if not all(geom_type in {"LineString"} for geom_type in segment_geom_types):
            msg = (
                f"segments_gdf must contain only LineString geometries. "
                f"Found: {', '.join(segment_geom_types)}"
            )
            raise ValueError(msg)


def _validate_single_gdf_input(
    gdf: gpd.GeoDataFrame,
    gdf_name: str,
    expected_geom_types: set[str],
) -> None:
    """
    Validate a single GeoDataFrame input.

    Parameters
    ----------
    gdf : geopandas.GeoDataFrame
        GeoDataFrame to validate.
    gdf_name : str
        Name of the GeoDataFrame (for error messages).
    expected_geom_types : set[str]
        Set of expected geometry types (e.g., {"Polygon", "MultiPolygon"}).

    Raises
    ------
    TypeError
        If gdf is not a GeoDataFrame.
    ValueError
        If geometry types are invalid and gdf is not empty.
    """
    # Check if the input is a GeoDataFrame
    if not isinstance(gdf, gpd.GeoDataFrame):
        msg = f"{gdf_name} must be a GeoDataFrame"
        raise TypeError(msg)

    # If GeoDataFrame is not empty, validate its geometry types
    if not gdf.empty:
        actual_geom_types = gdf.geometry.geom_type.unique() # Get unique geometry types present
        # Check if all actual types are within the set of expected types
        if not all(geom_type in expected_geom_types for geom_type in actual_geom_types):
            msg = (
                f"{gdf_name} must contain only {', '.join(sorted(expected_geom_types))} geometries. "
                f"Found: {', '.join(sorted(actual_geom_types))}"
            )
            raise ValueError(msg) # Raise error if unexpected types are found


def _ensure_crs_consistency(target_gdf: gpd.GeoDataFrame, source_gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
    """
    Ensure CRS consistency between two GeoDataFrames.

    Parameters
    ----------
    target_gdf : geopandas.GeoDataFrame
        Target GeoDataFrame with the desired CRS
    source_gdf : geopandas.GeoDataFrame
        Source GeoDataFrame to potentially reproject

    Returns
    -------
    geopandas.GeoDataFrame
        Source GeoDataFrame reprojected to target CRS if necessary

    Warns
    -----
    RuntimeWarning
        If CRS mismatch is detected and reprojection is performed
    """
    # Check if CRS of source_gdf matches target_gdf
    if source_gdf.crs != target_gdf.crs:
        warnings.warn("CRS mismatch detected, reprojecting", RuntimeWarning, stacklevel=3) # Warn user
        return source_gdf.to_crs(target_gdf.crs) # Reproject source_gdf to target_gdf's CRS
    return source_gdf # Return source_gdf as is if CRSs match


def _prepare_barriers(
    segments: gpd.GeoDataFrame,
    geom_col: str | None,
) -> gpd.GeoDataFrame:
    """
    Prepare barrier geometries for tessellation.

    Parameters
    ----------
    segments : geopandas.GeoDataFrame
        Street segments GeoDataFrame
    geom_col : str, optional
        Alternative geometry column name

    Returns
    -------
    geopandas.GeoDataFrame
        Prepared barriers GeoDataFrame
    """
    # If an alternative geometry column is specified, exists, and is not the default 'geometry'
    if geom_col and geom_col in segments.columns and geom_col != "geometry":
        # Create a new GeoDataFrame using the alternative geometry column as the active geometry
        return gpd.GeoDataFrame(
            segments.drop(columns=["geometry"]), # Drop the original 'geometry' column
            geometry=segments[geom_col], # Set the alternative column as the geometry
            crs=segments.crs, # Preserve CRS
        )
    return segments.copy() # Otherwise, return a copy of the original segments


def _filter_adjacent_tessellation(
    tess: gpd.GeoDataFrame,
    segments: gpd.GeoDataFrame,
    max_distance: float = math.inf,
) -> gpd.GeoDataFrame:
    """
    Filter tessellation to only include cells adjacent to segments.

    Parameters
    ----------
    tess : geopandas.GeoDataFrame
        Tessellation GeoDataFrame
    segments : geopandas.GeoDataFrame
        Street segments GeoDataFrame to measure distance against.
    max_distance : float, optional
        Maximum Euclidean distance between tessellation centroids and the
        nearest segment (from the `segments` GeoDataFrame).
        In `morphological_graph`, this is typically derived from `distance + clipping_buffer`
        if `distance` is specified, or `math.inf` otherwise.
        If ``tess`` contains an ``enclosure_index`` column,
        distances are measured using only segments intersecting each enclosure.
        Defaults to ``math.inf`` which retains all cells.

    Returns
    -------
    geopandas.GeoDataFrame
        Filtered tessellation
    """
    # If tessellation is empty, return an empty GeoDataFrame with the same structure
    if tess.empty:
        return tess.copy()

    # If max_distance is infinite, no filtering is needed based on distance
    if math.isinf(max_distance):
        return tess.copy()

    # Check if 'enclosure_index' column exists for grouped processing
    encl_col = "enclosure_index" if "enclosure_index" in tess.columns else None

    # List to store filtered parts of tessellation
    filtered_parts: list[gpd.GeoDataFrame] = []

    # Iterate over each enclosure group
    for _, group in tess.groupby(encl_col):
        # Geometry of the current enclosure
        enclosure_geom = group.unary_union

        # Segments intersecting this enclosure
        segs_in_enclosure = segments[segments.intersects(enclosure_geom)]

        # Union of segments within this enclosure
        segment_union_in_enclosure = segs_in_enclosure.unary_union

        # Centroids of cells in this group
        centroids_in_group = group.geometry.centroid

        # Distances to segments in this enclosure
        distances_in_group = centroids_in_group.distance(segment_union_in_enclosure)

        # Filter cells in group by distance
        filtered_group = group.loc[distances_in_group <= max_distance]

        # Add filtered group to list
        if not filtered_group.empty:
            filtered_parts.append(filtered_group)

    # Concatenate all filtered parts into a single GeoDataFrame
    return gpd.GeoDataFrame(pd.concat(filtered_parts), crs=tess.crs)


def _build_spatial_graph(
    segments: gpd.GeoDataFrame,
    tess_centroids: gpd.GeoSeries,
) -> tuple[nx.Graph, dict[int, str], dict[str, tuple[float, float]]]:
    """Build a spatial graph from segments and tessellation centroids."""
    # Convert segment GeoDataFrame to a NetworkX graph; nodes are segment endpoints, edges are segments
    graph = gdf_to_nx(edges=segments)
    # Get positions (coordinates) of segment graph nodes
    seg_nodes_pos_dict = nx.get_node_attributes(graph, "pos")

    # Create unique node IDs for each tessellation centroid based on its iloc (integer location)
    centroid_iloc_to_node_id = {i: f"tess_centroid_{i}" for i, _ in enumerate(tess_centroids)}
    # Prepare new nodes (tessellation centroids) to add to the graph with their positions
    new_nodes_for_graph = [
        (f"tess_centroid_{i}", {"pos": (pt.x, pt.y), "type": "centroid_node"})
        for i, pt in enumerate(tess_centroids) # pt is a Shapely Point object
    ]
    # Add tessellation centroid nodes to the graph
    graph.add_nodes_from(new_nodes_for_graph)
    return graph, centroid_iloc_to_node_id, seg_nodes_pos_dict # Return graph and mappings


def _connect_centroids_to_segment_graph(
    graph: nx.Graph,
    centroids: gpd.GeoSeries, # GeoSeries of tessellation centroid Points
    centroid_iloc_to_node_id: dict[int, str], # Maps centroid iloc to graph node ID
    seg_nodes_pos_dict: dict[str, tuple[float, float]], # Positions of segment graph nodes
) -> None:
    """Connect centroid nodes to the nearest segment graph nodes using KDTree."""
    # Prepare segment node IDs and their coordinates for KDTree
    seg_node_ids_list = list(seg_nodes_pos_dict.keys())
    seg_node_coords_list = [list(coord) for coord in seg_nodes_pos_dict.values()]
    seg_node_coords_array = np.array(seg_node_coords_list)

    # Build KDTree from segment graph node coordinates for efficient nearest neighbor search
    tree = KDTree(seg_node_coords_array)

    # Prepare centroid coordinates for querying the KDTree
    centroid_coords_list = [(pt.x, pt.y) for pt in centroids.tolist()]
    centroid_coords_array = np.array(centroid_coords_list)

    # Query KDTree: for each centroid, find the nearest segment graph node and distance to it
    distances_to_seg, indices_in_seg_nodes = tree.query(centroid_coords_array)

    # Prepare edges to connect centroids to their nearest segment graph nodes
    edges_to_add = [
        (
            centroid_iloc_to_node_id[i],  # Graph node ID of the i-th centroid
            seg_node_ids_list[indices_in_seg_nodes[i]],  # Graph node ID of the nearest segment node
            {"length": distances_to_seg[i]},  # Euclidean distance as edge length
        )
        for i in range(len(centroids)) # Iterate through each centroid
        if 0 <= indices_in_seg_nodes[i] < len(seg_node_ids_list)  # Ensure index is valid
    ]
    # Add the new edges to the graph
    if edges_to_add:
        graph.add_edges_from(edges_to_add)


def _connect_centroids_to_centroids(
    graph: nx.Graph,
    centroids: gpd.GeoSeries, # Assumed to be a GeoSeries of Point geometries
    centroid_iloc_to_node_id: dict[int, str], # Maps iloc of centroids to graph node_id
) -> None:
    """Connect centroid nodes to each other based on Euclidean distance, vectorized."""
    # Get relevant ilocs (integer positions) from the centroid_iloc_to_node_id map and sort them
    relevant_ilocs = sorted(centroid_iloc_to_node_id.keys())

    # Extract centroid Point geometries and their graph node IDs in a consistent, sorted order
    points_to_connect = centroids.iloc[relevant_ilocs] # GeoSeries of Points
    node_ids_ordered = [centroid_iloc_to_node_id[iloc] for iloc in relevant_ilocs] # List of node IDs

    # Create a 2D NumPy array of coordinates (x, y) from the Point geometries
    coords_array = np.array([(pt.x, pt.y) for pt in points_to_connect])

    # Calculate all pairwise Euclidean distances using scipy.spatial.distance.pdist
    # pdist returns a condensed distance matrix (a 1D array of upper triangular part)
    pairwise_distances = pdist(coords_array, metric="euclidean")

    edges_to_add = [] # List to store edges to be added to the graph
    # Generate all unique pairs of ordered node IDs using itertools.combinations
    # The order of pairs matches the order of distances in pairwise_distances
    for idx, (node_id1, node_id2) in enumerate(itertools.combinations(node_ids_ordered, 2)):
        distance = pairwise_distances[idx] # Get the corresponding distance
        edges_to_add.append((node_id1, node_id2, {"length": distance})) # Prepare edge tuple

    # Add all new centroid-to-centroid edges to the graph
    if edges_to_add:
        graph.add_edges_from(edges_to_add)

def _find_closest_node_to_center(
    graph: nx.Graph,
    center_point_geom: Point, # Geographic center point (Shapely Point)
) -> str | None:
    """Find the graph node closest to the geographic center point, vectorized."""
    # Get positions (coordinates) of all nodes in the graph
    all_node_pos_dict = nx.get_node_attributes(graph, "pos")

    # Convert node positions to a NumPy array of coordinates
    node_coords = np.array([list(pos) for pos in all_node_pos_dict.values() if pos is not None])

    # Filter node_ids to match the successfully converted and valid coordinates
    # This ensures node_ids and node_coords are aligned.
    valid_node_data = {
        nid: pos for nid, pos in all_node_pos_dict.items()
        if pos is not None and isinstance(pos, tuple) and len(pos) == 2 # Check for valid position tuple
    }

    # Extract valid node IDs and their coordinates
    node_ids = list(valid_node_data.keys()) # List of node IDs with valid positions
    node_coords = np.array(list(valid_node_data.values())) # NumPy array of valid coordinates

    # Ensure center_point_geom is a Point and extract its coordinates
    center_coord = np.array([center_point_geom.x, center_point_geom.y]) # Coordinates of the center point

    # Calculate squared Euclidean distances from all nodes to the center point (avoids sqrt for comparison)
    distances_sq = np.sum((node_coords - center_coord)**2, axis=1)

    # Find the index of the minimum squared distance
    closest_idx = np.argmin(distances_sq)
    # Return the ID of the closest node
    return node_ids[closest_idx]


def _filter_nodes_by_path_length(
    graph: nx.Graph,
    source_node_id: str, # Starting node for path length calculation
    max_distance: float, # Maximum allowed path length
    centroid_iloc_to_node_id: dict[int, str], # Mapping from centroid iloc to graph node ID
) -> list[int]: # Returns list of ilocs of centroids within max_distance
    # Calculate shortest path lengths from source_node_id to all other nodes
    lengths = nx.single_source_dijkstra_path_length(graph, source_node_id, weight="length")

    # Filter centroid ilocs based on whether their corresponding node's path length is within max_distance
    return [
        iloc # Keep the iloc of the centroid
        for iloc, node_id in centroid_iloc_to_node_id.items() # Iterate through centroid mappings
        # Check if path length to centroid node is <= max_distance
        if lengths.get(node_id, math.inf) <= max_distance
    ]


def _filter_tessellation_by_network_distance(
    tess: gpd.GeoDataFrame,
    segments: gpd.GeoDataFrame,
    center_point: gpd.GeoSeries | gpd.GeoDataFrame | Point, # Geographic center for filtering
    max_distance: float, # Maximum network distance
) -> gpd.GeoDataFrame:
    """Filter tessellation by network distance from a center point."""
    # Return a copy of tessellation if it or segments are empty
    if tess.empty or segments.empty:
        return tess.copy()

    # Get centroids of tessellation cells
    centroids = tess.geometry.centroid
    # Build a spatial graph including segment endpoints and tessellation centroids as nodes
    graph, centroid_iloc_to_node_id, seg_nodes_pos_dict = _build_spatial_graph(segments, centroids)

    # Connect tessellation centroid nodes to the nearest segment graph nodes
    _connect_centroids_to_segment_graph(
        graph, centroids, centroid_iloc_to_node_id, seg_nodes_pos_dict,
    )
    # Connect tessellation centroid nodes to each other (e.g., for paths through open spaces)
    _connect_centroids_to_centroids(graph, centroids, centroid_iloc_to_node_id)

    # Normalize center_point input to a single Shapely Point geometry
    center_geom = center_point.iloc[0] if isinstance(center_point, gpd.GeoSeries) else center_point

    # Find the graph node closest to the geographic center_geom
    center_node_id_in_graph = _find_closest_node_to_center(graph, center_geom)

    # Filter centroid ilocs based on network path length from the center_node_id_in_graph
    keep_ilocs = _filter_nodes_by_path_length(
        graph, center_node_id_in_graph, max_distance, centroid_iloc_to_node_id,
    )

    # Return the subset of the original tessellation corresponding to the kept ilocs
    return tess.iloc[sorted(keep_ilocs)].copy()


def _add_building_info(
    tess: gpd.GeoDataFrame,
    buildings: gpd.GeoDataFrame,
) -> gpd.GeoDataFrame:
    """
    Add building information to tessellation.

    Parameters
    ----------
    tess : geopandas.GeoDataFrame
        Tessellation GeoDataFrame
    buildings : geopandas.GeoDataFrame
        Buildings GeoDataFrame

    Returns
    -------
    geopandas.GeoDataFrame
        Tessellation with building information
    """
    # If no buildings are provided, return the tessellation as is
    if buildings.empty:
        return tess.copy()

    # Perform a spatial join (left join) from tessellation to buildings based on intersection
    # This adds columns from 'buildings' to 'tess' for intersecting features.
    # 'index_right' column is added by sjoin, containing the index of the joined building.
    joined = gpd.sjoin(tess, buildings, how="left", predicate="intersects")

    # If 'index_right' exists (meaning some joins occurred), map building geometries
    if "index_right" in joined.columns:
        # Create a mapping from building index to building geometry
        building_geom_map = buildings.geometry.to_dict()
        # Use the 'index_right' (building indices) to look up geometries from the map
        # This creates a pandas Series of Shapely geometries.
        building_geometries_series = joined["index_right"].map(building_geom_map)
        # Convert this pandas Series to a GeoSeries, assigning the CRS from the source 'buildings' GDF
        joined["building_geometry"] = gpd.GeoSeries(building_geometries_series, crs=buildings.crs)
        # Remove the temporary 'index_right' column
        joined = joined.drop(columns=["index_right"])
    return joined # Return tessellation with added building geometry (if any)


def _create_empty_edges_gdf(
    crs: str | int | None,
    from_col: str, # Name for the 'from' node ID column
    to_col: str,   # Name for the 'to' node ID column
    extra_cols: list[str] | None = None, # Optional list of additional column names
) -> gpd.GeoDataFrame:
    """
    Create an empty edges GeoDataFrame with specified column structure.

    Parameters
    ----------
    crs : str, int, or None
        Coordinate reference system
    from_col : str
        Name of the 'from' ID column
    to_col : str
        Name of the 'to' ID column
    extra_cols : list[str], optional
        Additional columns to include

    Returns
    -------
    geopandas.GeoDataFrame
        Empty GeoDataFrame with specified columns
    """
    # Initialize list of column names with 'from' and 'to' ID columns
    columns = [from_col, to_col]
    # Add any extra columns if provided
    if extra_cols:
        columns.extend(extra_cols)
    # Add the 'geometry' column name (standard for GeoDataFrames)
    columns.append("geometry")

    # Create an empty GeoDataFrame with the defined columns, geometry column, and CRS
    return gpd.GeoDataFrame(columns=columns, geometry="geometry", crs=crs)


def _set_node_index(gdf: gpd.GeoDataFrame, col: str) -> gpd.GeoDataFrame:
    """Set GeoDataFrame index using a specified column, if it exists.

    Parameters
    ----------
    gdf : geopandas.GeoDataFrame
        Input GeoDataFrame
    col : str
        Column name to use as index

    Returns
    -------
    geopandas.GeoDataFrame
        GeoDataFrame with index set if column exists
    """
    if gdf.empty:
        # For an empty GDF, set an empty index.
        # Attempting to set_index with a non-existent column `col` would error.
        # If `col` is the intended index name, it can be assigned after.
        return gdf.set_index(pd.Index([])) # Safest for empty

    return gdf.set_index(col, drop=True)

def _set_edge_index(
    gdf: gpd.GeoDataFrame,
    from_col: str, # Column name for the 'from' part of the MultiIndex
    to_col: str,   # Column name for the 'to' part of the MultiIndex
) -> gpd.GeoDataFrame:
    """
    Set multi-index for edge GeoDataFrame.

    Parameters
    ----------
    gdf : geopandas.GeoDataFrame
        Edge GeoDataFrame
    from_col : str
        'From' column name
    to_col : str
        'To' column name

    Returns
    -------
    geopandas.GeoDataFrame
        GeoDataFrame with multi-index set
    """
    # If GDF is not empty and both 'from_col' and 'to_col' exist, set a MultiIndex
    if not gdf.empty and from_col in gdf.columns and to_col in gdf.columns:
        return gdf.set_index([from_col, to_col]) # Set MultiIndex using the two columns
    return gdf # Otherwise, return GDF unchanged (e.g., if empty or columns missing)


# ============================================================================
# HELPER FUNCTIONS FOR SPATIAL WEIGHTS AND ADJACENCY
# ============================================================================


def _create_spatial_weights(gdf: gpd.GeoDataFrame, contiguity: str) -> libpysal.weights.W | None:
    """
    Create spatial weights matrix for adjacency analysis.

    Parameters
    ----------
    gdf : geopandas.GeoDataFrame
        Input GeoDataFrame with polygon geometries
    contiguity : str
        Type of contiguity ("queen" or "rook")

    Returns
    -------
    libpysal.weights.W or None
        Spatial weights matrix, or None if creation fails
    """
    # Attempt to create spatial weights matrix using libpysal
    if contiguity == "queen": # Queen contiguity (shared edges or vertices)
        return libpysal.weights.Queen.from_dataframe(gdf)

    # Rook contiguity (shared edges only)
    return libpysal.weights.Rook.from_dataframe(gdf)

def _extract_adjacency_relationships(
    spatial_weights: libpysal.weights.W, # Precomputed spatial weights matrix
    gdf: gpd.GeoDataFrame, # GeoDataFrame from which weights were computed (indexed 0..N-1)
    id_col: str, # Name of the column in 'gdf' containing the actual polygon IDs
    group_col: str | None, # Optional column name for grouping adjacencies
) -> pd.DataFrame:
    """
    Extract adjacency relationships from spatial weights matrix.

    Parameters
    ----------
    spatial_weights : libpysal.weights.W
        Spatial weights matrix
    gdf : geopandas.GeoDataFrame
        Input GeoDataFrame
    id_col : str
        ID column name
    group_col : str, optional
        Group column name for filtering

    Returns
    -------
    pandas.DataFrame
        DataFrame with adjacency relationships
    """
    # Convert spatial weights to COO (Coordinate Format) sparse matrix for easier pair extraction
    coo = spatial_weights.sparse.tocoo()
    # Create a mask to get only unique pairs (upper triangle, row < col) to avoid duplicates (i,j) and (j,i)
    mask = coo.row < coo.col
    rows = coo.row[mask] # Indices of 'from' polygons (based on gdf's 0..N-1 index)
    cols = coo.col[mask] # Indices of 'to' polygons (based on gdf's 0..N-1 index)

    # Extract the actual polygon IDs using the 'id_col' from the input 'gdf'
    from_ids = gdf.iloc[rows][id_col].to_numpy() # Actual IDs for 'from' polygons
    to_ids = gdf.iloc[cols][id_col].to_numpy()   # Actual IDs for 'to' polygons

    # If grouping is specified, filter adjacencies to only include pairs within the same group
    if group_col:
        grp_i = gdf.iloc[rows][group_col].to_numpy() # Group values for 'from' polygons
        grp_j = gdf.iloc[cols][group_col].to_numpy() # Group values for 'to' polygons
        valid_group_mask = grp_i == grp_j # Mask for pairs in the same group

        # Apply group filter to indices and IDs
        rows = rows[valid_group_mask]
        cols = cols[valid_group_mask]
        from_ids = from_ids[valid_group_mask]
        to_ids = to_ids[valid_group_mask]
        groups = grp_i[valid_group_mask] # Group values for the valid pairs
    else:
        # If no grouping, assign a default group "all" to all pairs
        groups = np.full(len(from_ids), "all", dtype=object)
        group_col = "group" # Set group_col name for the output DataFrame

    # Filter out self-loops (though coo.row < coo.col should prevent this for simple IDs)
    # This is an additional safeguard, especially if id_col might not be perfectly unique per geometry.
    valid_ids_filter = from_ids != to_ids
    from_ids = from_ids[valid_ids_filter]
    to_ids = to_ids[valid_ids_filter]
    groups = groups[valid_ids_filter]
    rows = rows[valid_ids_filter] # Keep 'rows' and 'cols' consistent for centroid lookup later
    cols = cols[valid_ids_filter]

    # Return a DataFrame containing the adjacency relationships
    return pd.DataFrame({
        "row": rows, # Original 0..N-1 index of 'from' polygon in gdf_indexed
        "col": cols, # Original 0..N-1 index of 'to' polygon in gdf_indexed
        "from_private_id": from_ids, # Actual ID of 'from' polygon
        "to_private_id": to_ids,     # Actual ID of 'to' polygon
        group_col: groups,           # Group identifier for the pair
    })


def _create_adjacency_edges(
    adjacency_data: pd.DataFrame, # DataFrame from _extract_adjacency_relationships
    gdf: gpd.GeoDataFrame, # Original private_gdf, indexed 0..N-1, used for centroid lookup
    group_col: str, # Name of the group column in adjacency_data
) -> pd.DataFrame: # Returns a DataFrame, to be converted to GeoDataFrame by caller
    """
    Create edge geometries from adjacency relationships.

    Parameters
    ----------
    adjacency_data : pandas.DataFrame
        DataFrame with adjacency relationships (must include 'row', 'col',
        'from_private_id', 'to_private_id', and group_col columns)
    gdf : geopandas.GeoDataFrame
        Input GeoDataFrame with geometries (assumed to have a simple 0..N-1 index
        corresponding to 'row'/'col' in adjacency_data)
    group_col : str
        Group column name present in adjacency_data

    Returns
    -------
    pandas.DataFrame
        DataFrame with edge geometries
    """
    # Work with a copy to avoid modifying the input DataFrame
    adj_data_processed = adjacency_data.copy()

    # Sort ID pairs to ensure canonical representation (e.g., (A,B) not (B,A)) for deduplication
    id_pairs = adj_data_processed[["from_private_id", "to_private_id"]].to_numpy()
    sorted_id_pairs = np.sort(id_pairs, axis=1) # Sort each pair [id1, id2]
    adj_data_processed["from_private_id"] = sorted_id_pairs[:, 0] # Assign smaller ID to 'from'
    adj_data_processed["to_private_id"] = sorted_id_pairs[:, 1]   # Assign larger ID to 'to'

    # Drop duplicate edges based on the sorted (from_id, to_id) and group
    adj_data_processed = adj_data_processed.drop_duplicates(
        subset=["from_private_id", "to_private_id", group_col],
    )

    # Calculate centroids of all polygons in the input GeoDataFrame 'gdf'
    # 'gdf' is assumed to be the one with 0..N-1 index matching 'row'/'col' in adjacency_data
    centroids = gdf.geometry.centroid

    # Get the 0..N-1 indices for 'from' and 'to' polygons from adjacency_data
    rows_idx = adj_data_processed["row"].to_numpy() # Indices for 'from' centroids
    cols_idx = adj_data_processed["col"].to_numpy() # Indices for 'to' centroids

    # Look up centroid geometries using these indices
    points_p1 = centroids.iloc[rows_idx] # Centroids of 'from' polygons
    points_p2 = centroids.iloc[cols_idx] # Centroids of 'to' polygons

    # Extract (x,y) coordinates for p1 and p2 centroids
    coords_p1 = np.array(list(zip(points_p1.x, points_p1.y, strict=True)))
    coords_p2 = np.array(list(zip(points_p2.x, points_p2.y, strict=True)))

    # Stack coordinates to form pairs for LineString creation [(x1,y1), (x2,y2)]
    line_coords = np.stack((coords_p1, coords_p2), axis=1)

    # Create LineStrings and assign to the 'geometry' column
    adj_data_processed["geometry"] = list(sh_linestrings(line_coords))

    # Drop intermediate 'row' and 'col' index columns if they exist
    columns_to_drop = [col for col in ["row", "col"] if col in adj_data_processed.columns]

    # Define final columns for the output DataFrame
    final_columns = ["from_private_id", "to_private_id", group_col, "geometry"]

    # Return the processed DataFrame with selected columns
    return adj_data_processed.drop(columns=columns_to_drop)[final_columns]
